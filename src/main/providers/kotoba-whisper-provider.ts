import { STTProvider, STTTranscriptionResult, STTProviderConfig } from '../stt-provider';
import { EventEmitter } from 'events';
import * as path from 'path';
import * as fs from 'fs';
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

export interface KotobaWhisperConfig extends STTProviderConfig {
  modelPath?: string;
  device?: 'cpu' | 'cuda';
  batchSize?: number;
  chunkLength?: number;
  language?: string;
  temperature?: number;
  suppressBlank?: boolean;
  wordTimestamps?: boolean;
}

export class KotobaWhisperProvider extends STTProvider {
  private tempDir: string;
  private chunkCounter = 0;
  private audioBuffer: Buffer[] = [];
  private modelPath: string;
  private device: 'cpu' | 'cuda';
  private batchSize: number;
  private chunkLength: number;
  private temperature: number;
  private suppressBlank: boolean;
  private wordTimestamps: boolean;

  constructor(config: KotobaWhisperConfig) {
    super(config);
    this.modelPath = config.modelPath || 'kotoba-tech/kotoba-whisper-v2.0';
    this.device = config.device || 'cpu';
    this.batchSize = config.batchSize || 1;
    this.chunkLength = config.chunkLength || 15;
    this.temperature = config.temperature || 0;
    this.suppressBlank = config.suppressBlank !== false;
    this.wordTimestamps = config.wordTimestamps || false;
    
    this.tempDir = require('os').tmpdir();
  }

  async initialize(): Promise<boolean> {
    try {
      console.log('ğŸ¤ KotobaWhisperProvider: åˆæœŸåŒ–é–‹å§‹');
      
      // Pythonç’°å¢ƒã¨transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
      await this.checkPythonEnvironment();
      
      // ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç¢ºèª
      await this.checkModelAvailability();
      
      console.log('ğŸ¤ KotobaWhisperProvider: åˆæœŸåŒ–å®Œäº†');
      return true;
    } catch (error) {
      console.error('ğŸ¤ KotobaWhisperProvider: åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
      return false;
    }
  }

  private async checkPythonEnvironment(): Promise<void> {
    try {
      const { stdout } = await execAsync('python3 --version');
      console.log('ğŸ¤ Pythonç’°å¢ƒç¢ºèª:', stdout.trim());
      
      // transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
      try {
        await execAsync('python3 -c "import transformers; print(transformers.__version__)"');
        console.log('ğŸ¤ transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¢ºèª: OK');
      } catch (error) {
        console.log('ğŸ¤ transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...');
        await execAsync('pip3 install transformers torch datasets');
      }
    } catch (error) {
      throw new Error('Python3ç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Python3ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚');
    }
  }

  private async checkModelAvailability(): Promise<void> {
    try {
      const script = `
import torch
from transformers import pipeline

try:
    pipe = pipeline(
        "automatic-speech-recognition",
        model="${this.modelPath}",
        torch_dtype=torch.float32,
        device="${this.device}"
    )
    print("Model loaded successfully")
except Exception as e:
    print(f"Error loading model: {e}")
    exit(1)
`;
      
      const { stdout } = await execAsync(`python3 -c "${script}"`);
      console.log('ğŸ¤ ãƒ¢ãƒ‡ãƒ«ç¢ºèª:', stdout.trim());
    } catch (error) {
      console.log('ğŸ¤ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...');
      // ãƒ¢ãƒ‡ãƒ«ã®åˆå›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
      await this.downloadModel();
    }
  }

  private async downloadModel(): Promise<void> {
    console.log('ğŸ¤ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...');
    
    const scriptPath = path.join(this.tempDir, 'download_model.py');
    const script = `
import torch
from transformers import pipeline

print("Downloading kotoba-whisper-v2.0 model...")
pipe = pipeline(
    "automatic-speech-recognition",
    model="${this.modelPath}",
    torch_dtype=torch.float32,
    device="${this.device}"
)
print("Model downloaded successfully")
`;
    
    try {
      fs.writeFileSync(scriptPath, script);
      await execAsync(`python3 "${scriptPath}"`);
      fs.unlinkSync(scriptPath); // ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      console.log('ğŸ¤ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†');
    } catch (error) {
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      if (fs.existsSync(scriptPath)) {
        fs.unlinkSync(scriptPath);
      }
      throw new Error(`ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error}`);
    }
  }

  async startStreaming(): Promise<void> {
    console.log('ğŸ¤ KotobaWhisperProvider: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹');
    this.isStreaming = true;
    this.audioBuffer = [];
    this.chunkCounter = 0;
    this.emit('streamingStarted');
  }

  async stopStreaming(): Promise<void> {
    console.log('ğŸ¤ KotobaWhisperProvider: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åœæ­¢');
    this.isStreaming = false;
    this.audioBuffer = [];
    this.emit('streamingStopped');
  }

  async sendAudioData(data: Buffer): Promise<void> {
    if (!this.isStreaming) {
      throw new Error('ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“');
    }

    try {
      // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
      this.audioBuffer.push(data);
      
      // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ5ç§’åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒãŸã¾ã£ãŸã‚‰å‡¦ç†ï¼‰
      const totalSize = this.audioBuffer.reduce((sum: number, buffer: Buffer) => sum + buffer.length, 0);
      const targetSize = (this.config.sampleRate || 16000) * 5 * 2; // 5ç§’åˆ†ã®16bitéŸ³å£°ãƒ‡ãƒ¼ã‚¿
      
      if (totalSize >= targetSize) {
        await this.processAudioBuffer();
      }
    } catch (error) {
      console.error('ğŸ¤ éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  private async processAudioBuffer(): Promise<void> {
    if (this.audioBuffer.length === 0) {
      return;
    }

    try {
      // ãƒãƒƒãƒ•ã‚¡ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
      const audioData = Buffer.concat(this.audioBuffer);
      this.audioBuffer = [];

      // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
      const tempFilePath = path.join(this.tempDir, `kotoba_whisper_${Date.now()}.wav`);
      await this.saveAudioToFile(audioData, tempFilePath);

      // Kotoba Whisperã§æ–‡å­—èµ·ã“ã—
      const result = await this.transcribeWithKotobaWhisper(tempFilePath);

      // çµæœã‚’ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ç™ºè¡Œ
      const transcriptionResult: STTTranscriptionResult = {
        text: result.text,
        confidence: result.confidence || 0.8,
        language: result.language || 'ja',
        isFinal: true,
        timestamp: Date.now(),
        segments: result.segments || [],
      };

      this.emit('transcriptionResult', transcriptionResult);

      // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      fs.unlinkSync(tempFilePath);
    } catch (error) {
      console.error('ğŸ¤ éŸ³å£°ãƒãƒƒãƒ•ã‚¡å‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
      this.emit('error', error);
    }
  }

  private async transcribeWithKotobaWhisper(audioFilePath: string): Promise<any> {
    const scriptPath = path.join(this.tempDir, 'transcribe.py');
    const script = `
import torch
import json
import sys
from transformers import pipeline

try:
    # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    pipe = pipeline(
        "automatic-speech-recognition",
        model="${this.modelPath}",
        torch_dtype=torch.float32,
        device="${this.device}",
        model_kwargs={"attn_implementation": "sdpa"} if torch.cuda.is_available() else {}
    )
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—
    result = pipe(
        "${audioFilePath}",
        generate_kwargs={
            "language": "${this.config.language}",
            "task": "transcribe"
        },
        return_timestamps=True
    )
    
    # çµæœã‚’JSONå½¢å¼ã§å‡ºåŠ›
    output = {
        "text": result["text"],
        "language": "${this.config.language}",
        "segments": []
    }
    
    if "chunks" in result:
        for chunk in result["chunks"]:
            output["segments"].append({
                "start": chunk["timestamp"][0],
                "end": chunk["timestamp"][1],
                "text": chunk["text"],
                "confidence": 0.8
            })
    
    print(json.dumps(output, ensure_ascii=False))
    
except Exception as e:
    error_output = {"error": str(e)}
    print(json.dumps(error_output, ensure_ascii=False))
    sys.exit(1)
`;

    try {
      fs.writeFileSync(scriptPath, script);
      const { stdout } = await execAsync(`python3 "${scriptPath}"`);
      fs.unlinkSync(scriptPath); // ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      
      const result = JSON.parse(stdout);
      
      if (result.error) {
        throw new Error(result.error);
      }
      
      return result;
    } catch (error) {
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      if (fs.existsSync(scriptPath)) {
        fs.unlinkSync(scriptPath);
      }
      console.error('ğŸ¤ Kotoba Whisperæ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  private async saveAudioToFile(audioData: Buffer, filePath: string): Promise<void> {
    try {
      // WAVãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
      const sampleRate = this.config.sampleRate || 16000;
      const channels = this.config.channels || 1;
      const bitsPerSample = 16;
      
      const header = this.createWavHeader(audioData.length, sampleRate, channels, bitsPerSample);
      const wavData = Buffer.concat([header, audioData]);
      
      fs.writeFileSync(filePath, wavData);
    } catch (error) {
      console.error('ğŸ¤ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  private createWavHeader(dataLength: number, sampleRate: number, channels: number, bitsPerSample: number): Buffer {
    const header = Buffer.alloc(44);
    
    // RIFF header
    header.write('RIFF', 0);
    header.writeUInt32LE(36 + dataLength, 4);
    header.write('WAVE', 8);
    
    // fmt chunk
    header.write('fmt ', 12);
    header.writeUInt32LE(16, 16); // fmt chunk size
    header.writeUInt16LE(1, 20); // PCM format
    header.writeUInt16LE(channels, 22);
    header.writeUInt32LE(sampleRate, 24);
    header.writeUInt32LE(sampleRate * channels * bitsPerSample / 8, 28); // byte rate
    header.writeUInt16LE(channels * bitsPerSample / 8, 32); // block align
    header.writeUInt16LE(bitsPerSample, 34);
    
    // data chunk
    header.write('data', 36);
    header.writeUInt32LE(dataLength, 40);
    
    return header;
  }

  getProviderType(): string {
    return 'kotoba-whisper';
  }

  getProviderName(): string {
    return 'Kotoba Whisper v2.0';
  }

  isStreamingActive(): boolean {
    return this.isStreaming;
  }

  getSupportedLanguages(): string[] {
    return ['ja', 'en'];
  }

  getSupportedModels(): string[] {
    return ['kotoba-tech/kotoba-whisper-v2.0'];
  }

  async transcribeFile(filePath: string): Promise<STTTranscriptionResult> {
    try {
      const result = await this.transcribeWithKotobaWhisper(filePath);
      
      return {
        text: result.text,
        confidence: result.confidence || 0.8,
        language: result.language || 'ja',
        isFinal: true,
        timestamp: Date.now(),
        segments: result.segments || [],
      };
    } catch (error) {
      console.error('ğŸ¤ ãƒ•ã‚¡ã‚¤ãƒ«æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  async getModelInfo(): Promise<any> {
    return {
      name: 'kotoba-tech/kotoba-whisper-v2.0',
      version: '2.0',
      description: 'Japanese-optimized Whisper model',
      language: 'Japanese',
      speed: '6.3x faster than large-v3',
      accuracy: 'Better CER/WER than large-v3 for Japanese',
    };
  }
} 
